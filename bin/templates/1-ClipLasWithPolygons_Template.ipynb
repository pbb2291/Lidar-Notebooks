{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c8e78c8-1fcd-414d-b653-cc54be3fc6c7",
   "metadata": {},
   "source": [
    "# Clipping Las Files with Polygon Features\n",
    "***Davies Lab Lidar Script***<br>\n",
    "Peter Boucher <br>\n",
    "2022/09/23 <br>\n",
    "\n",
    "<p>This is the first step in a 2 part process for clipping las files with a set of polygons (1-ClipLasWithPolygons.ipynb) and then, computing vegetation structure metrics from the las files for each polygon (2-ComputeMetricsByPolygon.ipynb). </p>\n",
    "\n",
    "#### Inputs: \n",
    "- a shapefile of polygon features with a unique integer ID attribute for each polygon feature\n",
    "- a folder of las files (i.e. tiled point cloud data)\n",
    "    - If computing metrics (2-ComputeMetricsByPolygon.ipynb), the input las files need to have a \"Height\" attribute for each point (height above ground)\n",
    "\n",
    "#### Outputs:\n",
    "- a folder of clipped las files, with one file per feature, named by the unique id from the input shapefile\n",
    "\n",
    "## Define User Inputs Below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f0b685a-2058-4323-92a7-4fb71ed39487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append('../bin/')\n",
    "from LabLidar_Functions import lasClip_IndivFeature\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "import laspy\n",
    "import time\n",
    "\n",
    "# # #\n",
    "# # # USER INPUTS\n",
    "\n",
    "# Path to a shapefile (.shp) of polygon features to clip the point cloud with.\n",
    "shpf = Path('../data/in/test/shapefile/MpalaForestGEOCanopies_LabLidarTest_EPSG32637.shp')\n",
    "\n",
    "# Input directory of las files (usually in square tiles).\n",
    "ld = Path('../data/in/test/lasfileinputs/')\n",
    "\n",
    "# Output directory for clipped las files\n",
    "od = Path('../data/out/test/clippedlasfiles/')\n",
    "\n",
    "# EPSG code of the shapefile and the las files, as a string\n",
    "# Note: Shapefiles and las files must have the same EPSG code (same CRS)\n",
    "# Kruger is 32736 (WGS84 UTM 36S)\n",
    "# Mpala is 32637 (WGS84 UTM 37N)\n",
    "epsg='32637'\n",
    "\n",
    "# feature id column - name of attribute column in shapefile which defines each polygon feature with a unique ID\n",
    "featureIDcol = 'treeID'\n",
    "\n",
    "# # # End User Inputs\n",
    "# # # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf2cfa8-96a4-4f0f-8fda-f8c066e36cd7",
   "metadata": {},
   "source": [
    "#### 1) Load shapefile inputs, and perform quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10321374-72f7-4309-903a-7da2aa975bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the shapefile as a geodataframe\n",
    "# Note: Expects a file with polygon features only\n",
    "shpdf = gpd.read_file(str(shpf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5639850-9e97-4aff-9b7f-0fda5fb1f696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality Check for duplicate feature IDS\n",
    "\n",
    "# Checks if there is a unique ID for each polygon feature.\n",
    "# Otherwise, you can get multiple polygons, overwriting issues, etc.\n",
    "\n",
    "# Check for duplicate ids by filtering\n",
    "shpdf_nodupes = shpdf[featureIDcol].drop_duplicates()\n",
    "\n",
    "# If there are duplicates\n",
    "if shpdf_nodupes.shape[0] < shpdf.shape[0]:\n",
    "    \n",
    "    numberofdupes = shpdf.shape[0] - shpdf_nodupes.shape[0]\n",
    "    \n",
    "    q = input(f\"{numberofdupes} duplicate IDs found. Make new feature id and continue? y/n \\n\")\n",
    "    \n",
    "    if q == \"y\":\n",
    "    \n",
    "        # sort the file by the original index\n",
    "        shpdf.sort_values(by=featureIDcol, inplace=True)\n",
    "\n",
    "        # Make a new column with a unique index (row number) to identify each feature with\n",
    "        shpdf['FeatureID'] = shpdf.index\n",
    "\n",
    "        # Set the featureIDcol value to be this new column:\n",
    "        featureIDcol = 'FeatureID'\n",
    "\n",
    "        # save new shapefile for future reference\n",
    "        # make the new shapefile name\n",
    "        oshp_name = shpf.name.split('.')[0] + '_NewFeatureID.shp'\n",
    "        \n",
    "        # set the output folder to be in same as the input file\n",
    "        newshpf = Path(str(shpf.parent) + oshp_name)\n",
    "        \n",
    "        # Save it\n",
    "        shpdf.to_file(str(newshpf))\n",
    "        \n",
    "        print(f'New shapefile {newshpf.name} with FeatureID saved in {newshpf.anchor}/ \\n')\n",
    "        \n",
    "    if q == \"n\":\n",
    "        \n",
    "        print('Operation cancelled. Provide a new shapefile with unique feature IDs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0fd7379-475f-466f-ac0f-3bc9353a76cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality Check for Polygon Features Only\n",
    "\n",
    "# Make a copy for testing \n",
    "shpdf_test = shpdf.copy(deep=True)\n",
    "shpdf_test.head()\n",
    "\n",
    "# Label all rows with multipolygons\n",
    "shpdf_test['NotPoly'] = shpdf_test.geometry.apply(lambda x: x.type != 'Polygon')\n",
    "\n",
    "if shpdf_test.loc[shpdf_test['NotPoly']].size > 0:\n",
    "    \n",
    "    numnonpolys = shpdf_test.loc[shpdf_test['NotPoly']].size[0]\n",
    "    \n",
    "    print(f'{numnonpolys} non-polygon features found. \\n')\n",
    "    \n",
    "    q = input('Discard non-polygon features and continue? y\\n')\n",
    "    \n",
    "    if q == 'y':\n",
    "        \n",
    "        # Filter it to only include Polygon features\n",
    "        shpdf = shpdf.query('NotPoly == False')\n",
    "        \n",
    "    else: \n",
    "        \n",
    "        print('Provide a new shapefile with only polygons and restart process.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dd22ba6-0de6-47b1-b76d-3363d84f0993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last quality check\n",
    "\n",
    "# make sure there aren't any LAS outputs already\n",
    "# If there are, point will be appended to each file \n",
    "lfs = [l for l in od.glob('*.las')]\n",
    "\n",
    "if len(lfs) > 0:\n",
    "    \n",
    "    print(f'WARNING: Output las files already found in directory: \\n \\t{od} \\n')\n",
    "    print('To avoid overwrite issues, delete all files in output directory before proceeding.\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b469d4f0-da74-4572-9a4a-32d8dfd4fdea",
   "metadata": {},
   "source": [
    "#### 2) Clip Las Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7866ab3-87fa-4f91-bb96-6f6fc2e80e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for running in parallel\n",
    "def lasClip_IndivFeature_Parallel(feat, IDcol=featureIDcol):\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        lasClip_IndivFeature(feature=feat,\n",
    "                             lasdir=ld,\n",
    "                             outdir=od,\n",
    "                             featureIDcol=featureIDcol,\n",
    "                             epsg=epsg,\n",
    "                             verb=False)\n",
    "    except:\n",
    "        \n",
    "        print(f'Issue with {IDcol}: {feat.get(IDcol)} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0431bcf-c821-46bd-a635-11a1d9e2f1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to clip 1698 polygon features... \n",
      "\n",
      "1698 features clipped in 2727.744031190872 s.\n"
     ]
    }
   ],
   "source": [
    "# Make a list of all features in shapefile to iterate through\n",
    "features = [f for i, f in shpdf.iterrows()]\n",
    "\n",
    "# Run tree clipping function\n",
    "start = time.time()\n",
    "\n",
    "print(f'Starting to clip {len(features)} polygon features... \\n')\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=None) as executor:\n",
    "        for f in zip(executor.map(lasClip_IndivFeature_Parallel, features)):\n",
    "            endi = time.time()\n",
    "    \n",
    "end = time.time()\n",
    "\n",
    "print(f'{len(features)} features clipped in {end-start} s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ca3962-2e35-4d1a-9045-76b74ef1adc1",
   "metadata": {},
   "source": [
    "# DONE!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lablidar]",
   "language": "python",
   "name": "conda-env-lablidar-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
