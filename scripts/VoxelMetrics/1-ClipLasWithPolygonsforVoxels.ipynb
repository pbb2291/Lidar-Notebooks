{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c8e78c8-1fcd-414d-b653-cc54be3fc6c7",
   "metadata": {},
   "source": [
    "# Clipping Las Files with Polygon Features\n",
    "***Lidar-Notebooks***<br>\n",
    "Peter Boucher <br>\n",
    "2022/11/29 <br>\n",
    "\n",
    "<p>This is the first step in a 3 part process for 1) clipping las files with a set of polygons (1-ClipLasWithPolygonsforVoxels.ipynb); 2) voxeling lidar data, computing vegetation structure metrics, and outputting a pickle file (2-ProcessVoxelMetrics.ipynb); and 3) outputting the pixel and voxel grids of each metric as geotif or netcdf files for use in qgis and other software (3-OutputVoxelMetrics_Geotiff_NetCDF.ipynb). </p>\n",
    "\n",
    "#### Inputs: \n",
    "- a shapefile of polygon features with a unique integer ID attribute for each polygon feature\n",
    "- a folder of las files (i.e. tiled point cloud data)\n",
    "    - If computing metrics (2-ComputeMetricsByPolygon.ipynb), the input las files need to have a \"Height\" attribute for each point (height above ground)\n",
    "\n",
    "#### Outputs:\n",
    "- a folder of clipped las files, with one file per feature, named by the unique id from the input shapefile\n",
    "\n",
    "## Define User Inputs Below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f0b685a-2058-4323-92a7-4fb71ed39487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append('../../bin/')\n",
    "from LabLidar_Functions import lasClip_IndivFeature\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "import laspy\n",
    "import time\n",
    "\n",
    "# # #\n",
    "# # # USER INPUTS\n",
    "\n",
    "# Path to a shapefile (.shp) of polygon features to clip the point cloud with.\n",
    "shpf = Path('/n/home02/pbb/scripts/halo-metadata-server/LabLidarScripts/data/in/test/shapefile/Nkhulu_polygon_FullandOpen_5mBuffer.shp')\n",
    "\n",
    "# Input directory of las files (usually in square tiles).\n",
    "ld = Path('/n/davies_lab/Lab/LabLidarScripts/data/out/test/nkhulu/las_preprocessed')\n",
    "\n",
    "# Output directory for clipped las files\n",
    "od = Path('/n/davies_lab/Lab/LabLidarScripts/data/out/test/nkhulu/las_clipped/')\n",
    "\n",
    "# EPSG code of the shapefile and the las files, as a string\n",
    "# Note: Shapefiles and las files must have the same EPSG code (same CRS)\n",
    "# Kruger is 32736 (WGS84 UTM 36S)\n",
    "# Mpala is 32637 (WGS84 UTM 37N)\n",
    "epsg='32636'\n",
    "\n",
    "# feature id column - name of attribute column in shapefile which defines each polygon feature with a unique ID\n",
    "featureIDcol = 'FeatureID'\n",
    "\n",
    "# TBD: Add a project name, or a date of processing\n",
    "# OR make a temp directory\n",
    "# To fix the issue of overwriting/appending duplicate points to\n",
    "# output las files \n",
    "\n",
    "# # # End User Inputs\n",
    "# # # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf2cfa8-96a4-4f0f-8fda-f8c066e36cd7",
   "metadata": {},
   "source": [
    "#### 1) Load shapefile inputs, and perform quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10321374-72f7-4309-903a-7da2aa975bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>Exclosure</th>\n",
       "      <th>TopoPositi</th>\n",
       "      <th>FeatureID</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Outside</td>\n",
       "      <td>Open</td>\n",
       "      <td>Lowland</td>\n",
       "      <td>OpenLowland</td>\n",
       "      <td>POLYGON ((375881.287 7236191.282, 375881.621 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Full</td>\n",
       "      <td>Lowland</td>\n",
       "      <td>FullLowland</td>\n",
       "      <td>POLYGON ((375847.146 7235803.347, 375847.528 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Outside</td>\n",
       "      <td>Open</td>\n",
       "      <td>Upland</td>\n",
       "      <td>OpenUpland</td>\n",
       "      <td>POLYGON ((376148.850 7235840.955, 376148.951 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Full</td>\n",
       "      <td>Upland</td>\n",
       "      <td>FullUpland</td>\n",
       "      <td>POLYGON ((376172.983 7235631.834, 376158.369 7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id Treatment Exclosure TopoPositi    FeatureID  \\\n",
       "0   2   Outside      Open    Lowland  OpenLowland   \n",
       "1   1    Inside      Full    Lowland  FullLowland   \n",
       "2   2   Outside      Open     Upland   OpenUpland   \n",
       "3   1    Inside      Full     Upland   FullUpland   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((375881.287 7236191.282, 375881.621 7...  \n",
       "1  POLYGON ((375847.146 7235803.347, 375847.528 7...  \n",
       "2  POLYGON ((376148.850 7235840.955, 376148.951 7...  \n",
       "3  POLYGON ((376172.983 7235631.834, 376158.369 7...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the shapefile as a geodataframe\n",
    "# Note: Expects a file with polygon features only\n",
    "shpdf = gpd.read_file(str(shpf))\n",
    "shpdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5639850-9e97-4aff-9b7f-0fda5fb1f696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality Check for duplicate feature IDS\n",
    "\n",
    "# Checks if there is a unique ID for each polygon feature.\n",
    "# Otherwise, you can get multiple polygons, overwriting issues, etc.\n",
    "\n",
    "# Check for duplicate ids by filtering\n",
    "shpdf_nodupes = shpdf[featureIDcol].drop_duplicates()\n",
    "\n",
    "# If there are duplicates\n",
    "if shpdf_nodupes.shape[0] < shpdf.shape[0]:\n",
    "    \n",
    "    numberofdupes = shpdf.shape[0] - shpdf_nodupes.shape[0]\n",
    "    \n",
    "    q = input(f\"{numberofdupes} duplicate IDs found.\\n\\tMake new attribute with unique Feature IDs and continue? y/n \\n\")\n",
    "    \n",
    "    if q == \"y\":\n",
    "    \n",
    "        # sort the file by the original index\n",
    "        shpdf.sort_values(by=featureIDcol, inplace=True)\n",
    "\n",
    "        # Make a new column with a unique index (row number) to identify each feature with\n",
    "        shpdf['FeatureID'] = shpdf.index\n",
    "\n",
    "        # Set the featureIDcol value to be this new column:\n",
    "        featureIDcol = 'FeatureID'\n",
    "\n",
    "        # save new shapefile for future reference\n",
    "        # make the new shapefile name\n",
    "        oshp_name = shpf.name.split('.')[0] + '_NewFeatureID.shp'\n",
    "        \n",
    "        # set the output folder to be in same as the input file\n",
    "        newshpf = Path(str(shpf.parent) + oshp_name)\n",
    "        \n",
    "        # Save it\n",
    "        shpdf.to_file(str(newshpf))\n",
    "        \n",
    "        print(f'New shapefile {newshpf.name} with FeatureID column saved in {newshpf.anchor}/ \\n')\n",
    "        \n",
    "    if q == \"n\":\n",
    "        \n",
    "        print('Operation cancelled. Provide a new shapefile with unique feature IDs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0fd7379-475f-466f-ac0f-3bc9353a76cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality Check for Polygon Features Only\n",
    "\n",
    "# Make a copy for testing \n",
    "shpdf_test = shpdf.copy(deep=True)\n",
    "shpdf_test.head()\n",
    "\n",
    "# Label all rows with multipolygons\n",
    "shpdf_test['NotPoly'] = shpdf_test.geometry.apply(lambda x: x.type != 'Polygon')\n",
    "\n",
    "if shpdf_test.loc[shpdf_test['NotPoly']].size > 0:\n",
    "    \n",
    "    numnonpolys = shpdf_test.loc[shpdf_test['NotPoly']].size[0]\n",
    "    \n",
    "    print(f'{numnonpolys} non-polygon features found. \\n')\n",
    "    \n",
    "    q = input('Discard non-polygon features and continue? y\\n')\n",
    "    \n",
    "    if q == 'y':\n",
    "        \n",
    "        # Filter it to only include Polygon features\n",
    "        shpdf = shpdf.query('NotPoly == False')\n",
    "        \n",
    "    else: \n",
    "        \n",
    "        print('Provide a new shapefile with only polygons and restart process.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dd22ba6-0de6-47b1-b76d-3363d84f0993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last quality check\n",
    "\n",
    "# make sure there aren't any LAS outputs already\n",
    "# If there are, point will be appended to each file \n",
    "lfs = [l for l in od.glob('*.las')]\n",
    "\n",
    "if len(lfs) > 0:\n",
    "    \n",
    "    print(f'WARNING: Output las files already found in directory: \\n \\t{od} \\n')\n",
    "    print('To avoid overwrite issues, delete all files in output directory before proceeding.\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b469d4f0-da74-4572-9a4a-32d8dfd4fdea",
   "metadata": {},
   "source": [
    "#### 2) Clip Las Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7866ab3-87fa-4f91-bb96-6f6fc2e80e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for running in parallel\n",
    "def lasClip_IndivFeature_Parallel(feat, IDcol=featureIDcol):\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        lasClip_IndivFeature(feature=feat,\n",
    "                             lasdir=ld,\n",
    "                             outdir=od,\n",
    "                             featureIDcol=featureIDcol,\n",
    "                             epsg=epsg,\n",
    "                             verb=False)\n",
    "    except:\n",
    "        \n",
    "        print(f'Issue with {IDcol}: {feat.get(IDcol)} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0431bcf-c821-46bd-a635-11a1d9e2f1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to clip 4 polygon features... \n",
      "\n",
      "4 features clipped in 1324.7125840187073 s.\n"
     ]
    }
   ],
   "source": [
    "# Make a list of all features in shapefile to iterate through\n",
    "features = [f for i, f in shpdf.iterrows()]\n",
    "\n",
    "# Run tree clipping function\n",
    "start = time.time()\n",
    "\n",
    "print(f'Starting to clip {len(features)} polygon features... \\n')\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=None) as executor:\n",
    "        for f in zip(executor.map(lasClip_IndivFeature_Parallel, features)):\n",
    "            endi = time.time()\n",
    "    \n",
    "end = time.time()\n",
    "\n",
    "print(f'{len(features)} features clipped in {end-start} s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ca3962-2e35-4d1a-9045-76b74ef1adc1",
   "metadata": {},
   "source": [
    "# DONE!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lablidar]",
   "language": "python",
   "name": "conda-env-lablidar-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
