{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4bacbd0-7acf-402a-9495-429533a5c681",
   "metadata": {},
   "source": [
    "### Outputting Grid Metrics as 2D and 3D Arrays\n",
    "*PB 2022/11/29*\n",
    "\n",
    "<p>This is the third step in a 3 part process for 1) clipping las files with a set of polygons (1-ClipLasWithPolygonsforVoxels.ipynb); 2) voxeling lidar data, computing vegetation structure metrics, and outputting a pickle file (2-ProcessVoxelMetrics.ipynb); and 3) outputting the pixel and voxel grids of each metric as geotif or netcdf files for use in qgis and other software (3-OutputVoxelMetrics_Geotiff_NetCDF.ipynb). </p>\n",
    "\n",
    "Based on OutputTifsandNetCDFs_3.ipy in Structural Complexity Mpala Project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f863cdb2-5ec4-40c5-9fc1-f08c9a6fbec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('/n/home02/pbb/scripts/halo-metadata-server/LabLidarScripts/bin/')\n",
    "sys.path.append('../../bin/')\n",
    "from LabLidar_Functions import fill2Darray, classifyVeg_GGW, classifyVeg_GGST\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import time\n",
    "import laspy\n",
    "from shapely.geometry import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45d7a9cd-00ab-4f7d-bcad-38a01a921b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # USER INPUTS: \n",
    "\n",
    "# Input Data:\n",
    "\n",
    "# Set the pickle metrics to draw from\n",
    "metricdir = Path('/n/davies_lab/Lab/LabLidarScripts/data/out/test/nkhulu/pickle_metrics')\n",
    "\n",
    "# Horizontal Grid size\n",
    "xysize = 0.5\n",
    "\n",
    "# Ground threshold\n",
    "groundthreshold = 0.05\n",
    "\n",
    "# Set CRS of las files\n",
    "# Kruger is 32736 (WGS84 UTM 36S)\n",
    "# Mpala is 32637 (WGS84 UTM 37N)\n",
    "# Selenkay is 32737 (WGS84 UTM37S)\n",
    "epsg='32736'\n",
    "\n",
    "# Shapefile of Plots\n",
    "# Note: Should be same shapefile as in Step 1-ClipLasWithPolygons\n",
    "shpf = Path('/n/home02/pbb/scripts/halo-metadata-server/LabLidarScripts/data/in/test/shapefile/Nkhulu_polygon_FullandOpen_5mBuffer.shp')\n",
    "shpdf = gpd.read_file(shpf)\n",
    "\n",
    "featureIDcol = 'FeatureID'\n",
    "\n",
    "# Output Data:\n",
    "\n",
    "# Outdirectory for rasters and netcdfs\n",
    "outdir_rast = Path('/n/davies_lab/Lab/LabLidarScripts/data/out/test/nkhulu/grid_metrics')\n",
    "\n",
    "# # #  END USER INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "513eb3d9-804f-4a44-802d-cb594f504230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of 3D metrics to output,\n",
    "# corresponding to the names in the saved cover dictionaries\n",
    "# Note: all percentile metrics get output by default\n",
    "metriclabels3d = ['Npulses', 'CoverD1', 'CoverD2', 'CoverD1byH', 'CoverD2byH', 'FHPD1', 'FHPD2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "59473579-c81c-4e43-b60d-7f96dd993ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th done\n",
      "25th done\n",
      "50th done\n",
      "75th done\n",
      "98th done\n",
      "100th done\n",
      "Mean done\n",
      "Std done\n",
      "vegtypeGGST done\n",
      "vegtypeGGW done\n",
      "nlayers done\n",
      "gapsize done\n",
      "maxpeakh done\n",
      "ptoh done\n",
      "cscore done\n",
      "FHD done\n",
      "VDR done\n",
      "meanpeakh done\n",
      "stdpeakh done\n",
      "cvpeakh done\n",
      "VDRpeak done\n",
      "herbh done\n",
      "Finished 2D outputs for FeatureID OpenLowland. 36.967984676361084 seconds. \n",
      "\n",
      "Finished 3D outputs for FeatureID OpenLowland. 156.4235806465149 seconds.\n",
      "\n",
      "0th done\n",
      "25th done\n",
      "50th done\n",
      "75th done\n",
      "98th done\n",
      "100th done\n",
      "Mean done\n",
      "Std done\n",
      "vegtypeGGST done\n",
      "vegtypeGGW done\n",
      "nlayers done\n",
      "gapsize done\n",
      "maxpeakh done\n",
      "ptoh done\n",
      "cscore done\n",
      "FHD done\n",
      "VDR done\n",
      "meanpeakh done\n",
      "stdpeakh done\n",
      "cvpeakh done\n",
      "VDRpeak done\n",
      "herbh done\n",
      "Finished 2D outputs for FeatureID FullLowland. 65.1310646533966 seconds. \n",
      "\n",
      "Finished 3D outputs for FeatureID FullLowland. 285.7783434391022 seconds.\n",
      "\n",
      "0th done\n",
      "25th done\n",
      "50th done\n",
      "75th done\n",
      "98th done\n",
      "100th done\n",
      "Mean done\n",
      "Std done\n",
      "vegtypeGGST done\n",
      "vegtypeGGW done\n",
      "nlayers done\n",
      "gapsize done\n",
      "maxpeakh done\n",
      "ptoh done\n",
      "cscore done\n",
      "FHD done\n",
      "VDR done\n",
      "meanpeakh done\n",
      "stdpeakh done\n",
      "cvpeakh done\n",
      "VDRpeak done\n",
      "herbh done\n",
      "Finished 2D outputs for FeatureID OpenUpland. 72.99162006378174 seconds. \n",
      "\n",
      "Finished 3D outputs for FeatureID OpenUpland. 271.6973955631256 seconds.\n",
      "\n",
      "0th done\n",
      "25th done\n",
      "50th done\n",
      "75th done\n",
      "98th done\n",
      "100th done\n",
      "Mean done\n",
      "Std done\n",
      "vegtypeGGST done\n",
      "vegtypeGGW done\n",
      "nlayers done\n",
      "gapsize done\n",
      "maxpeakh done\n",
      "ptoh done\n",
      "cscore done\n",
      "FHD done\n",
      "VDR done\n",
      "meanpeakh done\n",
      "stdpeakh done\n",
      "cvpeakh done\n",
      "VDRpeak done\n",
      "herbh done\n",
      "Finished 2D outputs for FeatureID FullUpland. 37.764145851135254 seconds. \n",
      "\n",
      "Finished 3D outputs for FeatureID FullUpland. 169.92179083824158 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sites to loop through\n",
    "Sites = [s for s in shpdf[featureIDcol]]\n",
    "\n",
    "# For each site/file name\n",
    "for s in Sites:\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    # Get organized:\n",
    "    # make output folders, as subdirectories for each file/site\n",
    "    # if they don't exist yet\n",
    "    if not Path(f'{outdir_rast}/{s}/').exists():\n",
    "        Path(f'{outdir_rast}/{s}/').mkdir()\n",
    "\n",
    "    # 1) Load Inputs, and Redefine Grid\n",
    "\n",
    "    # Load percentile height metric dict\n",
    "    with open(f'{metricdir}/{featureIDcol}_{s}_{xysize}mgrid_percmetrics.obj', 'rb') as of:\n",
    "        perc = pickle.load(of)\n",
    "\n",
    "    # Load Cover percentile dict\n",
    "    with open(f'{metricdir}/{featureIDcol}_{s}_{xysize}mgrid_covermetrics.obj', 'rb') as of:\n",
    "        cover = pickle.load(of)\n",
    "        \n",
    "    # Load Complexity dict\n",
    "    with open(f'{metricdir}/{featureIDcol}_{s}_{xysize}mgrid_complexitymetrics.obj', 'rb') as of                                                                                                                                                                                                                                                                                                                                    :\n",
    "        complexity = pickle.load(of)\n",
    "    \n",
    "    # Match site to get the plot polygon\n",
    "    feat_gs = shpdf.loc[shpdf[featureIDcol]==s]\n",
    "\n",
    "    # Set bounds of grid to fill\n",
    "    xmin=float(feat_gs.geometry.bounds.minx)\n",
    "    ymin=float(feat_gs.geometry.bounds.miny)\n",
    "    xmax=float(feat_gs.geometry.bounds.maxx)\n",
    "    ymax=float(feat_gs.geometry.bounds.maxy)\n",
    "\n",
    "    # Make the coordinates of the grid\n",
    "    x_grid = np.arange(xmin, xmax, step=xysize)\n",
    "    y_grid = np.arange(ymin, ymax, step=xysize)\n",
    "\n",
    "    # Mesh the grid into 2 matrices of x and y coordinates\n",
    "    x_mesh, y_mesh = np.meshgrid(x_grid, y_grid)\n",
    "\n",
    "    # Find the index of where all the data values belong in the grid\n",
    "    xlist = [k[0] for k in cover.keys()]\n",
    "    ylist = [k[1] for k in cover.keys()]\n",
    "\n",
    "    xidx = []\n",
    "    yidx = []\n",
    "\n",
    "    # for each unique x,y location in the list of data values\n",
    "    for x, y in zip(xlist, ylist):\n",
    "\n",
    "        # # Find it's unique x and y index location on the grid (ex: [0,1], [100,3], ...)        \n",
    "        # xi = np.flatnonzero(x_grid==x)\n",
    "        # yi = np.flatnonzero(y_grid==y)\n",
    "        \n",
    "       # Note: implemented the below, because I think there's a rounding error issue\n",
    "       # grid x_grid and xlist don't quite match, off by about 0.009 m\n",
    "       # 10/18/22\n",
    "        \n",
    "        # Find the closest value on the grid to make the index\n",
    "        # calculate the difference array\n",
    "        xdiff = np.absolute(x-x_grid)\n",
    "        # find the index of minimum element from the array\n",
    "        xindex = xdiff.argmin()\n",
    "        \n",
    "        # calculate the difference array\n",
    "        ydiff = np.absolute(y-y_grid)\n",
    "        # find the index of minimum element from the array\n",
    "        yindex = ydiff.argmin()\n",
    "        \n",
    "        xi = np.flatnonzero(x_grid==x_grid[xindex])\n",
    "        yi = np.flatnonzero(y_grid==y_grid[yindex])\n",
    "\n",
    "        # If there is a location (not empty)\n",
    "        if ((xi.size > 0) & (yi.size > 0)):\n",
    "\n",
    "            # Add to the list\n",
    "            xidx.append(xi[0])\n",
    "            yidx.append(yi[0])\n",
    "\n",
    "        else: \n",
    "\n",
    "            # Otherwise, mark them both with nans\n",
    "            xidx.append(np.nan)\n",
    "            yidx.append(np.nan)\n",
    "    \n",
    "    \n",
    "    # 2) Load, Reshape, and Output 2D Metrics\n",
    "\n",
    "    # Get all the data dicts from the nested perc dictionary\n",
    "    v = list(perc.values())\n",
    "\n",
    "    # unpack all vars into lists\n",
    "    perc0 = [i[0][0] for i in v]\n",
    "    perc25 = [i[25][0] for i in v]\n",
    "    perc50 = [i[50][0] for i in v]\n",
    "    perc75 = [i[75][0] for i in v]\n",
    "    perc98 = [i[98][0] for i in v]\n",
    "    perc100 = [i[100][0] for i in v]\n",
    "    meanh = [i['mean'][0] for i in v]\n",
    "    stdh = [i['std'][0] for i in v]\n",
    "    \n",
    "    # Classify Vegetation using 98th percentile height\n",
    "    vegtypeGGST = [classifyVeg_GGST(p, groundthreshold=groundthreshold) for p in perc98]\n",
    "    vegtypeGGW = [classifyVeg_GGW(p, groundthreshold=groundthreshold) for p in perc98]\n",
    "    \n",
    "    # Get all the data vals from the nested complexity dictionary\n",
    "    vc = list(complexity.values())\n",
    "\n",
    "    # unpack all vars into lists\n",
    "    nlayers = [i['nlayers'] for i in vc]\n",
    "    maxpeakh = [i['maxpeakh'] for i in vc]\n",
    "    gapsize = [i['gapsize'] for i in vc]\n",
    "    ptoh = [i['ptoh'] for i in vc]\n",
    "    cscore = [i['cscore'] for i in vc]\n",
    "    FHD = [i['FHD'] for i in vc]\n",
    "    VDR = [i['VDR'] for i in vc]\n",
    "    meanpeakh = [i['meanpeakh'] for i in vc]\n",
    "    stdpeakh = [i['stdpeakh'] for i in vc]\n",
    "    cvpeakh = [i['cvpeakh'] for i in vc]\n",
    "    VDRpeak = [i['VDRpeak'] for i in vc]\n",
    "    herbh = [i['herbh'] for i in vc]\n",
    "\n",
    "    # 'nlayers', 'gapsize', 'maxpeakh','ptoh', 'cscore', 'FHD', 'VDR', 'meanpeakh', 'stdpeakh', 'cvpeakh'\n",
    "    # nlayers, gapsize, maxpeakh, ptoh, cscore, FHD, VDR, meanpeakh, stdpeakh, cvpeakh\n",
    "\n",
    "    # Reshape vars into 2D arrays and store in a dictionary\n",
    "    outdict = {}.fromkeys(['0th','25th', '50th', '75th', '98th', '100th', 'Mean', 'Std', 'vegtypeGGST', 'vegtypeGGW',\n",
    "                           'nlayers', 'gapsize', 'maxpeakh','ptoh', 'cscore', 'FHD', 'VDR', 'meanpeakh', 'stdpeakh', 'cvpeakh', 'VDRpeak', 'herbh'])\n",
    "\n",
    "    for m, l in zip([perc0, perc25, perc50, perc75, perc98, perc100, meanh, stdh, vegtypeGGST, vegtypeGGW,\n",
    "                     nlayers, gapsize,maxpeakh, ptoh, cscore, FHD, VDR, meanpeakh, stdpeakh, cvpeakh, VDRpeak, herbh],\n",
    "                    ['0th','25th', '50th', '75th', '98th', '100th', 'Mean', 'Std', 'vegtypeGGST', 'vegtypeGGW',\n",
    "                     'nlayers', 'gapsize', 'maxpeakh','ptoh', 'cscore', 'FHD', 'VDR', 'meanpeakh', 'stdpeakh', 'cvpeakh', 'VDRpeak', 'herbh']):\n",
    "\n",
    "        outdict[l] = fill2Darray(data=m, shape=x_mesh.shape,\n",
    "                                 xindices=xidx, yindices=yidx, plot=False)\n",
    "\n",
    "    # Output 2D Arrays as geotifs\n",
    "    for l in ['0th','25th', '50th', '75th', '98th', '100th', 'Mean', 'Std', 'vegtypeGGST', 'vegtypeGGW',\n",
    "              'nlayers', 'gapsize', 'maxpeakh','ptoh', 'cscore', 'FHD', 'VDR', 'meanpeakh', 'stdpeakh', 'cvpeakh', 'VDRpeak', 'herbh']:\n",
    "\n",
    "        # Grab one metric for output\n",
    "        m = outdict[l]\n",
    "\n",
    "        # Mirror Image the metric\n",
    "        # Note: You do this because rioxarray wants data\n",
    "        # ordered with positive x (left to right)\n",
    "        # but with negative y (top to bottom)\n",
    "        # This really just makes the export to geotif go smoothly,\n",
    "        # with a correct affine transform \n",
    "        m = np.flipud(m)\n",
    "\n",
    "        # Also flip y coordinates, so that they're correctly read into x array\n",
    "        # y_grid_flip = np.flip(y_grid)\n",
    "        # NOTE: adding xysize to y coord so that it marks Top left corner\n",
    "        # instead of bottom left - this is in accordance with raster data and rioxarray\n",
    "        y_grid_flip = np.flip(y_grid) + xysize\n",
    "\n",
    "        # put in an xarray\n",
    "        # 2D\n",
    "        m_xr = xr.DataArray(data=m,\n",
    "                            coords={\"y\": y_grid_flip,\n",
    "                                    \"x\": x_grid},\n",
    "                            dims=[\"y\", \"x\"])\n",
    "\n",
    "        # Write CRS and Nodata value and dims to xarray\n",
    "        m_xr.rio.write_crs(f\"epsg:{epsg}\",\n",
    "                           inplace=True)\n",
    "        m_xr.rio.write_nodata(-9999,\n",
    "                              inplace=True)\n",
    "        m_xr.rio.set_spatial_dims(x_dim=\"x\",\n",
    "                                  y_dim=\"y\",\n",
    "                                  inplace=True)\n",
    "        m_xr.rio.write_coordinate_system(inplace=True)\n",
    "\n",
    "        # make an output Label\n",
    "        label = l.replace(' ', '').replace('.', 'p').replace('[m]', '')\n",
    "\n",
    "        m_xr.rio.to_raster(f'{outdir_rast}/{s}/{s}_{label}.tif')\n",
    "\n",
    "        print(f'{l} done')\n",
    "\n",
    "    end2d = time.time()\n",
    "\n",
    "    print(f'Finished 2D outputs for {featureIDcol} {s}. {end2d-start} seconds. \\n')\n",
    "\n",
    "    \n",
    "    # 3) Load, Reshape, and Output 3D Metrics\n",
    "\n",
    "    # Unpack cover values as a list\n",
    "    v3 = list(cover.values())\n",
    "\n",
    "    # Get list of heights for later\n",
    "    hbins = v3[0]['HeightBins']\n",
    "    \n",
    "    # Make shape for output array\n",
    "    # note - y, then x here\n",
    "    shape = (len(y_grid), len(x_grid))\n",
    "\n",
    "    # for each set of 3D metrics\n",
    "    for l3 in metriclabels3d:\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            # list to fill with xarrays from each height\n",
    "            xr_list = []\n",
    "\n",
    "            # Deals with an issue caused by using np.diff\n",
    "            # if there's a difference metric, then the last height does not have a value\n",
    "            if ((\"byH\" in l3) | ('FHP' in l3)) :\n",
    "                hbinz = hbins[0:-1]\n",
    "            else:\n",
    "                hbinz = hbins\n",
    "\n",
    "            # for each height bin\n",
    "            for hidx, h in enumerate(hbinz): \n",
    "\n",
    "                # make an array of all the values\n",
    "                m = np.array([i[l3][hidx] for i in v3])\n",
    "\n",
    "                # make an empty output array, filled with nans\n",
    "                output_array = np.full(shape, np.nan)\n",
    "\n",
    "                # Convert to int\n",
    "                xindices = np.array(xidx).astype(int)\n",
    "                yindices = np.array(yidx).astype(int)\n",
    "\n",
    "                # Fill any inf values in data with -9999\n",
    "                # data[np.isfinite(data, where=False)] = -9999\n",
    "\n",
    "                # stick into the array\n",
    "                # IMPORTANT: it's y, then x, not the other way around\n",
    "                output_array[yindices, xindices] = m\n",
    "\n",
    "                # Mirror Image the metric\n",
    "                # Note: You do this because rioxarray wants data\n",
    "                # ordered with positive x (left to right)\n",
    "                # but with negative y (top to bottom)\n",
    "                # This really just makes the export to geotif go smoothly,\n",
    "                # with a correct affine transform.\n",
    "                output_array = np.flipud(output_array)\n",
    "\n",
    "                # Also flip y coordinates, so that they're correctly read into x array \n",
    "                # Also, adding xysize to y coord so that it marks top left corner\n",
    "                # instead of bottom left - this is in accordance with raster data and rioxarray\n",
    "                y_grid_flip = np.flip(y_grid) + xysize\n",
    "\n",
    "                # put in an xarray - 2D\n",
    "                m_xr = xr.DataArray(data=output_array,\n",
    "                                    coords={\"y\": y_grid_flip,\n",
    "                                            \"x\": x_grid},\n",
    "                                    dims=[\"y\", \"x\"])\n",
    "\n",
    "                # Write CRS and Nodata value\n",
    "                m_xr.rio.write_crs(f\"epsg:{epsg}\", inplace=True)\n",
    "                m_xr.rio.write_nodata(-9999, inplace=True)\n",
    "                m_xr.rio.set_spatial_dims(x_dim=\"x\", y_dim=\"y\", inplace=True)\n",
    "                m_xr.rio.write_coordinate_system(inplace=True)\n",
    "\n",
    "                # add to list \n",
    "                xr_list.append(m_xr)\n",
    "\n",
    "            # Concatenate dataarrays\n",
    "            # https://docs.xarray.dev/en/stable/user-guide/combining.html#combine\n",
    "            # setting the values of the new dimension to be height\n",
    "            ds = xr.concat(xr_list, hbinz)\n",
    "            ds = ds.rename({'concat_dim':'z'})\n",
    "\n",
    "            # Set it's name\n",
    "            ds.name = l3\n",
    "\n",
    "            # output to netcdf\n",
    "            ds.to_netcdf(f'{outdir_rast}/{s}/{s}_{l3}.nc')\n",
    "        \n",
    "        except Exception as e:\n",
    "            \n",
    "            print(f'{e.__class__} - {e}.\\n\\tNo file output for {l3}.')\n",
    "            \n",
    "    end3d = time.time()\n",
    "\n",
    "    print(f'Finished 3D outputs for {featureIDcol} {s}. {end3d-start} seconds.\\n')\n",
    "\n",
    "print('Done outputting files.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517aa100-6334-4431-934f-21d6b50f2a71",
   "metadata": {},
   "source": [
    "### DONE - Testing Scratch Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7bbfd1-148a-4b04-b001-6b3dfc211a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Input directory of las files that metrics were made from\n",
    "# # NOTE: currently used to define the grid\n",
    "# ld = Path('/n/davies_lab/Lab/LabLidarScripts/data/out/test/lasfiles_preprocessed/Nkhulu')\n",
    "# make list of pickle strings to loop through\n",
    "# finds cover pickle files and grabs the output string from them\n",
    "# Names = [p.name.split('_0.')[0] for p in metricdir.glob('*cover*.obj')]\n",
    "\n",
    "\n",
    "#     # Get current las file that corresponds to these metrics\n",
    "#     lasf = f'{ld}/{s}.las'\n",
    "    \n",
    "#     # open the current las file for reading\n",
    "#     with laspy.open(lasf) as l:\n",
    "\n",
    "#         # Make las boundary points from header into a polygon (ul, ur, lr, ll, ul)\n",
    "#         # Ploygon is a shapely.geometry object\n",
    "#         lasbounds_poly = Polygon([[l.header.mins[0], l.header.maxs[1]],\n",
    "#                                   [l.header.maxs[0], l.header.maxs[1]],\n",
    "#                                   [l.header.maxs[0], l.header.mins[1]],\n",
    "#                                   [l.header.mins[0], l.header.mins[1]],\n",
    "#                                   [l.header.mins[0], l.header.maxs[1]]])\n",
    "\n",
    "#         # Make a geodataframe from the boundaries of the las file\n",
    "#         lasbounds_gdf = gpd.GeoDataFrame(geometry=[lasbounds_poly],\n",
    "#                                         crs=f'EPSG:{epsg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3e548ad-e878-4531-9642-a65bdf262e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure showing slight offset between coords in xlist (from cover_dict) and coords made with np.arange\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(x_mesh, y_mesh, s=2, c='b')\n",
    "# ax.scatter(xlist, ylist, s=2, c='k')\n",
    "# ax.axis('equal')\n",
    "# ax.margins(x=-0.49, y=-0.49) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6a4f9e8-2ec1-4222-9326-7ad47d6318d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(np.array(vegtypeGGST)[np.array(vegtypeGGST)>0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-Halo]",
   "language": "python",
   "name": "conda-env-.conda-Halo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
